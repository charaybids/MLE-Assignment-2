{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f1e2831",
   "metadata": {},
   "source": [
    "### Bronze Pipeline   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a3fa97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists\n",
      "\n",
      "Bronze Layer Completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('datamart/bronze') == False:\n",
    "    os.makedirs('datamart/bronze', exist_ok=True)\n",
    "    \n",
    "    bronze_featureCS = pd.read_csv('data/feature_clickstream.csv')\n",
    "    bronze_featureAttr = pd.read_csv('data/features_attributes.csv')\n",
    "    bronze_featureFin = pd.read_csv('data/features_financials.csv')\n",
    "    bronze_LMSloans = pd.read_csv('data/lms_loan_daily.csv')\n",
    "    print(\"CSV files read\")\n",
    "\n",
    "    for col in bronze_featureCS.columns:\n",
    "        bronze_featureCS[col] = bronze_featureCS[col].astype(str)\n",
    "\n",
    "    bronze_featureCS.info()\n",
    "\n",
    "    for col in bronze_featureAttr.columns:\n",
    "        bronze_featureAttr[col] = bronze_featureAttr[col].astype(str)\n",
    "\n",
    "    bronze_featureAttr.info()\n",
    "\n",
    "    for col in bronze_featureFin.columns:\n",
    "        bronze_featureFin[col] = bronze_featureFin[col].astype(str)\n",
    "\n",
    "    bronze_featureFin.info()\n",
    "\n",
    "    for col in bronze_LMSloans.columns:\n",
    "        bronze_LMSloans[col] = bronze_LMSloans[col].astype(str)\n",
    "\n",
    "    bronze_LMSloans.info()\n",
    "\n",
    "    print(\"columns converted to string\")\n",
    "\n",
    "    bronze_featureCS.to_parquet('datamart/bronze/feature_clickstream.parquet', index=False, compression='gzip', engine='pyarrow')\n",
    "    bronze_featureAttr.to_parquet('datamart/bronze/features_attributes.parquet', index=False, compression='gzip', engine='pyarrow')\n",
    "    bronze_featureFin.to_parquet('datamart/bronze/features_financials.parquet', index=False, compression='gzip', engine='pyarrow')\n",
    "    bronze_LMSloans.to_parquet('datamart/bronze/LMS_loans.parquet', index=False, compression='gzip', engine='pyarrow')\n",
    "\n",
    "    print(\"parquest files created\")\n",
    "    print(\"\\nData Ingestion Completed\")\n",
    "    \n",
    "else:\n",
    "    print(\"Directory already exists\")\n",
    "     \n",
    "\n",
    "\n",
    "print(\"\\nBronze Layer Completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e622c",
   "metadata": {},
   "source": [
    "### Spark Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1681806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def create_spark_session(app_name):\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(app_name) \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"16g\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    print(f\"Spark session '{app_name}' created successfully.\")\n",
    "    \n",
    "    return spark\n",
    "\n",
    "def stop_spark_session(spark):\n",
    "    spark.stop()\n",
    "    print(\"Spark session stopped.\")\n",
    "\n",
    "def read_parquet(spark, file_path):\n",
    "    df = spark.read.parquet(file_path)\n",
    "    print(f\"Data read from {file_path} successfully.\")\n",
    "    return df\n",
    "\n",
    "def write_parquet(df, file_path):\n",
    "    \"\"\"Write Spark DataFrame to single parquet file (like bronze layer)\"\"\"\n",
    "    # Convert Spark DataFrame to Pandas and save as single compressed parquet file\n",
    "    pandas_df = df.toPandas()\n",
    "    pandas_df.to_parquet(file_path, index=False, compression='gzip', engine='pyarrow')\n",
    "    print(f\"Data written to {file_path} successfully.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84dd407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session 'Data Cleaning' created successfully.\n",
      "Directory already exists\n",
      "Data read from datamart/bronze/feature_clickstream.parquet successfully.\n",
      "Data read from datamart/bronze/features_attributes.parquet successfully.\n",
      "Data read from datamart/bronze/features_financials.parquet successfully.\n",
      "Data read from datamart/bronze/LMS_loans.parquet successfully.\n",
      "parquet files read\n",
      "Data read from datamart/bronze/LMS_loans.parquet successfully.\n",
      "parquet files read\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "spark = create_spark_session(\"Data Cleaning\")\n",
    "\n",
    "if os.path.exists('datamart\\silver') == False:\n",
    "    os.makedirs('datamart\\silver', exist_ok=True)\n",
    "else:\n",
    "    print(\"Directory already exists\")\n",
    "    \n",
    "    silver_featureCS = read_parquet(spark, 'datamart/bronze/feature_clickstream.parquet')\n",
    "    silver_featureAttr = read_parquet(spark, 'datamart/bronze/features_attributes.parquet')\n",
    "    silver_featureFin = read_parquet(spark, 'datamart/bronze/features_financials.parquet')\n",
    "    silver_LMSloans = read_parquet(spark, 'datamart/bronze/LMS_loans.parquet')\n",
    "    print(\"parquet files read\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def remove_flagged_customers(silver_dfs, flagged_customers):\n",
    "    \"\"\"Remove flagged customers from all datasets\"\"\"\n",
    "    print(\"Remove Flagged Customers\\n\")\n",
    "    filtered_dfs = {}\n",
    "    for name, df in silver_dfs.items():\n",
    "        before = df.count()\n",
    "        filtered_df = df.join(flagged_customers, on='Customer_ID', how='left_anti')\n",
    "        after = filtered_df.count()\n",
    "        removed = before - after\n",
    "        print(f\"  {name:15} - Removed {removed:5} rows ({before} → {after})\")\n",
    "        filtered_dfs[name] = filtered_df\n",
    "    print(\"\\nRemoved\\n\")\n",
    "    return filtered_dfs\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f6fc186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing dates with format d/M/yyyy\n",
      "Parsed 5 date columns\n",
      "\n",
      "Cleaning attributes dataset\n",
      "Replaced placeholders ('_______', '_') with NULL in Occupation\n",
      "Cleaned Age with r\"[^0-9]\" → IntegerType\n",
      "Flagged invalid Age/SSN\n",
      "\n",
      "Cleaning financials dataset\n",
      "Replaced placeholders ('_', 'NM', '!@9#%8') with NULL in 3 categorical columns\n",
      "Cleaned 9 columns with r\"[^0-9.]\" → FloatType\n",
      "Cleaned 6 columns with r\"[^0-9]\" → IntegerType\n",
      "Flagged negative financial values\n",
      "\n",
      "Cleaning loan_daily dataset...\n",
      "Cleaned 7 columns with r\"[^0-9]\" → IntegerType\n",
      "Flagged negative loan values\n",
      "\n",
      "Cleaning clickstream dataset\n",
      "Cleaned 20 features (fe_1 to fe_20) with r\"[^0-9-]\" → IntegerType\n",
      "\n",
      "Identifying flagged customers\n",
      "Cleaned 20 features (fe_1 to fe_20) with r\"[^0-9-]\" → IntegerType\n",
      "\n",
      "Identifying flagged customers\n",
      "Flagged 1633/12500 customers (13.06%) for removal\n",
      "\n",
      "Remove Flagged Customers\n",
      "\n",
      "Flagged 1633/12500 customers (13.06%) for removal\n",
      "\n",
      "Remove Flagged Customers\n",
      "\n",
      "  attributes      - Removed  1633 rows (12500 → 10867)\n",
      "  attributes      - Removed  1633 rows (12500 → 10867)\n",
      "  financials      - Removed  1633 rows (12500 → 10867)\n",
      "  financials      - Removed  1633 rows (12500 → 10867)\n",
      "  loan_daily      - Removed 17963 rows (137500 → 119537)\n",
      "  loan_daily      - Removed 17963 rows (137500 → 119537)\n",
      "  clickstream     - Removed 28296 rows (215376 → 187080)\n",
      "\n",
      "Removed\n",
      "\n",
      "\n",
      "ATTRIBUTES DataFrame Info:\n",
      "  clickstream     - Removed 28296 rows (215376 → 187080)\n",
      "\n",
      "Removed\n",
      "\n",
      "\n",
      "ATTRIBUTES DataFrame Info:\n",
      "Rows: 10867\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- SSN: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "\n",
      "FINANCIALS DataFrame Info:\n",
      "Rows: 10867\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- SSN: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "\n",
      "FINANCIALS DataFrame Info:\n",
      "Rows: 10867\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- Annual_Income: float (nullable = true)\n",
      " |-- Monthly_Inhand_Salary: float (nullable = true)\n",
      " |-- Num_Bank_Accounts: integer (nullable = true)\n",
      " |-- Num_Credit_Card: integer (nullable = true)\n",
      " |-- Interest_Rate: float (nullable = true)\n",
      " |-- Num_of_Loan: integer (nullable = true)\n",
      " |-- Type_of_Loan: string (nullable = true)\n",
      " |-- Delay_from_due_date: integer (nullable = true)\n",
      " |-- Num_of_Delayed_Payment: integer (nullable = true)\n",
      " |-- Changed_Credit_Limit: float (nullable = true)\n",
      " |-- Num_Credit_Inquiries: integer (nullable = true)\n",
      " |-- Credit_Mix: string (nullable = true)\n",
      " |-- Outstanding_Debt: float (nullable = true)\n",
      " |-- Credit_Utilization_Ratio: float (nullable = true)\n",
      " |-- Credit_History_Age: string (nullable = true)\n",
      " |-- Payment_of_Min_Amount: string (nullable = true)\n",
      " |-- Total_EMI_per_month: float (nullable = true)\n",
      " |-- Amount_invested_monthly: float (nullable = true)\n",
      " |-- Payment_Behaviour: string (nullable = true)\n",
      " |-- Monthly_Balance: float (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "\n",
      "LOAN_DAILY DataFrame Info:\n",
      "Rows: 10867\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- Annual_Income: float (nullable = true)\n",
      " |-- Monthly_Inhand_Salary: float (nullable = true)\n",
      " |-- Num_Bank_Accounts: integer (nullable = true)\n",
      " |-- Num_Credit_Card: integer (nullable = true)\n",
      " |-- Interest_Rate: float (nullable = true)\n",
      " |-- Num_of_Loan: integer (nullable = true)\n",
      " |-- Type_of_Loan: string (nullable = true)\n",
      " |-- Delay_from_due_date: integer (nullable = true)\n",
      " |-- Num_of_Delayed_Payment: integer (nullable = true)\n",
      " |-- Changed_Credit_Limit: float (nullable = true)\n",
      " |-- Num_Credit_Inquiries: integer (nullable = true)\n",
      " |-- Credit_Mix: string (nullable = true)\n",
      " |-- Outstanding_Debt: float (nullable = true)\n",
      " |-- Credit_Utilization_Ratio: float (nullable = true)\n",
      " |-- Credit_History_Age: string (nullable = true)\n",
      " |-- Payment_of_Min_Amount: string (nullable = true)\n",
      " |-- Total_EMI_per_month: float (nullable = true)\n",
      " |-- Amount_invested_monthly: float (nullable = true)\n",
      " |-- Payment_Behaviour: string (nullable = true)\n",
      " |-- Monthly_Balance: float (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "\n",
      "LOAN_DAILY DataFrame Info:\n",
      "Rows: 119537\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- loan_id: string (nullable = true)\n",
      " |-- loan_start_date: date (nullable = true)\n",
      " |-- tenure: integer (nullable = true)\n",
      " |-- installment_num: integer (nullable = true)\n",
      " |-- loan_amt: integer (nullable = true)\n",
      " |-- due_amt: integer (nullable = true)\n",
      " |-- paid_amt: integer (nullable = true)\n",
      " |-- overdue_amt: integer (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "\n",
      "CLICKSTREAM DataFrame Info:\n",
      "Rows: 119537\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- loan_id: string (nullable = true)\n",
      " |-- loan_start_date: date (nullable = true)\n",
      " |-- tenure: integer (nullable = true)\n",
      " |-- installment_num: integer (nullable = true)\n",
      " |-- loan_amt: integer (nullable = true)\n",
      " |-- due_amt: integer (nullable = true)\n",
      " |-- paid_amt: integer (nullable = true)\n",
      " |-- overdue_amt: integer (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "\n",
      "CLICKSTREAM DataFrame Info:\n",
      "Rows: 187080\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- fe_1: integer (nullable = true)\n",
      " |-- fe_2: integer (nullable = true)\n",
      " |-- fe_3: integer (nullable = true)\n",
      " |-- fe_4: integer (nullable = true)\n",
      " |-- fe_5: integer (nullable = true)\n",
      " |-- fe_6: integer (nullable = true)\n",
      " |-- fe_7: integer (nullable = true)\n",
      " |-- fe_8: integer (nullable = true)\n",
      " |-- fe_9: integer (nullable = true)\n",
      " |-- fe_10: integer (nullable = true)\n",
      " |-- fe_11: integer (nullable = true)\n",
      " |-- fe_12: integer (nullable = true)\n",
      " |-- fe_13: integer (nullable = true)\n",
      " |-- fe_14: integer (nullable = true)\n",
      " |-- fe_15: integer (nullable = true)\n",
      " |-- fe_16: integer (nullable = true)\n",
      " |-- fe_17: integer (nullable = true)\n",
      " |-- fe_18: integer (nullable = true)\n",
      " |-- fe_19: integer (nullable = true)\n",
      " |-- fe_20: integer (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "Silver Cleaning Complete\n",
      "\n",
      "Rows: 187080\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- fe_1: integer (nullable = true)\n",
      " |-- fe_2: integer (nullable = true)\n",
      " |-- fe_3: integer (nullable = true)\n",
      " |-- fe_4: integer (nullable = true)\n",
      " |-- fe_5: integer (nullable = true)\n",
      " |-- fe_6: integer (nullable = true)\n",
      " |-- fe_7: integer (nullable = true)\n",
      " |-- fe_8: integer (nullable = true)\n",
      " |-- fe_9: integer (nullable = true)\n",
      " |-- fe_10: integer (nullable = true)\n",
      " |-- fe_11: integer (nullable = true)\n",
      " |-- fe_12: integer (nullable = true)\n",
      " |-- fe_13: integer (nullable = true)\n",
      " |-- fe_14: integer (nullable = true)\n",
      " |-- fe_15: integer (nullable = true)\n",
      " |-- fe_16: integer (nullable = true)\n",
      " |-- fe_17: integer (nullable = true)\n",
      " |-- fe_18: integer (nullable = true)\n",
      " |-- fe_19: integer (nullable = true)\n",
      " |-- fe_20: integer (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "Silver Cleaning Complete\n",
      "\n",
      "Data written to datamart/silver\\attributes.parquet successfully.\n",
      "Saved attributes\n",
      "Data written to datamart/silver\\attributes.parquet successfully.\n",
      "Saved attributes\n",
      "Data written to datamart/silver\\financials.parquet successfully.\n",
      "Saved financials\n",
      "Data written to datamart/silver\\financials.parquet successfully.\n",
      "Saved financials\n",
      "Data written to datamart/silver\\loan_daily.parquet successfully.\n",
      "Saved loan_daily\n",
      "Data written to datamart/silver\\loan_daily.parquet successfully.\n",
      "Saved loan_daily\n",
      "Data written to datamart/silver\\clickstream.parquet successfully.\n",
      "Saved clickstream\n",
      "Save Complete\n",
      "\n",
      "Data written to datamart/silver\\clickstream.parquet successfully.\n",
      "Saved clickstream\n",
      "Save Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parse dates (d/M/yyyy format)\n",
    "print(\"Parsing dates with format d/M/yyyy\")\n",
    "silver_featureAttr = silver_featureAttr.withColumn('snapshot_date', F.to_date('snapshot_date', 'd/M/yyyy'))\n",
    "silver_featureFin = silver_featureFin.withColumn('snapshot_date', F.to_date('snapshot_date', 'd/M/yyyy'))\n",
    "silver_LMSloans = silver_LMSloans.withColumn('snapshot_date', F.to_date('snapshot_date', 'd/M/yyyy')) \\\n",
    "                             .withColumn('loan_start_date', F.to_date('loan_start_date', 'd/M/yyyy'))\n",
    "silver_featureCS = silver_featureCS.withColumn('snapshot_date', F.to_date('snapshot_date', 'd/M/yyyy'))\n",
    "print(\"Parsed 5 date columns\\n\")\n",
    "\n",
    "# --- ATTRIBUTES CLEANING ---\n",
    "print(\"Cleaning attributes dataset\")\n",
    "# Replace placeholders with NULL\n",
    "silver_featureAttr = silver_featureAttr.withColumn('Occupation', \n",
    "    F.when(F.trim(F.col('Occupation')).isin('_______', '_'), None).otherwise(F.col('Occupation')))\n",
    "print(\"Replaced placeholders ('_______', '_') with NULL in Occupation\")\n",
    "\n",
    "# Clean Age: remove non-digits, cast to integer (handle empty strings)\n",
    "silver_featureAttr = silver_featureAttr.withColumn('Age', \n",
    "    F.when(F.trim(F.regexp_replace('Age', r'[^0-9]', '')) == '', None)\n",
    "     .otherwise(F.regexp_replace('Age', r'[^0-9]', '').cast(IntegerType())))\n",
    "print(\"Cleaned Age with r\\\"[^0-9]\\\" → IntegerType\")\n",
    "\n",
    "# Flag quality issues\n",
    "silver_featureAttr = silver_featureAttr \\\n",
    "    .withColumn('age_flag', F.when((F.col('Age') < 18) | (F.col('Age') > 100), 1).otherwise(0)) \\\n",
    "    .withColumn('ssn_flag', F.when(F.trim(F.col('SSN')).rlike(r'^\\d{3}-\\d{2}-\\d{4}$'), 0).otherwise(1)) \\\n",
    "    .withColumn('data_quality_issue', F.when((F.col('age_flag') == 1) | (F.col('ssn_flag') == 1), 1).otherwise(0))\n",
    "print(\"Flagged invalid Age/SSN\\n\")\n",
    "\n",
    "# --- FINANCIALS CLEANING ---\n",
    "print(\"Cleaning financials dataset\")\n",
    "# Replace categorical placeholders with NULL\n",
    "for col_name in ['Credit_Mix', 'Payment_of_Min_Amount', 'Payment_Behaviour']:\n",
    "    silver_featureFin = silver_featureFin.withColumn(col_name,\n",
    "        F.when(F.trim(F.col(col_name)).isin('_______', '_', 'NM', '!@9#%8'), None).otherwise(F.col(col_name)))\n",
    "print(\"Replaced placeholders ('_', 'NM', '!@9#%8') with NULL in 3 categorical columns\")\n",
    "\n",
    "# Clean float columns: keep digits and decimal point only (handle empty strings)\n",
    "float_cols = ['Annual_Income', 'Monthly_Inhand_Salary', 'Outstanding_Debt', \n",
    "              'Total_EMI_per_month', 'Amount_invested_monthly', 'Monthly_Balance',\n",
    "              'Changed_Credit_Limit', 'Interest_Rate', 'Credit_Utilization_Ratio']\n",
    "for col_name in float_cols:\n",
    "    silver_featureFin = silver_featureFin.withColumn(col_name,\n",
    "        F.when(F.trim(F.regexp_replace(col_name, r'[^0-9.]', '')) == '', None)\n",
    "         .otherwise(F.regexp_replace(col_name, r'[^0-9.]', '').cast(FloatType())))\n",
    "print(f\"Cleaned {len(float_cols)} columns with r\\\"[^0-9.]\\\" → FloatType\")\n",
    "\n",
    "# Clean integer columns: keep digits only (handle empty strings)\n",
    "int_cols = ['Num_of_Loan', 'Num_Bank_Accounts', 'Num_Credit_Card', \n",
    "            'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Num_Credit_Inquiries']\n",
    "for col_name in int_cols:\n",
    "    silver_featureFin = silver_featureFin.withColumn(col_name,\n",
    "        F.when(F.trim(F.regexp_replace(col_name, r'[^0-9]', '')) == '', None)\n",
    "         .otherwise(F.regexp_replace(col_name, r'[^0-9]', '').cast(IntegerType())))\n",
    "print(f\"Cleaned {len(int_cols)} columns with r\\\"[^0-9]\\\" → IntegerType\")\n",
    "\n",
    "# Flag quality issues\n",
    "silver_featureFin = silver_featureFin \\\n",
    "    .withColumn('negative_financials_flag', F.when(\n",
    "        (F.col('Annual_Income') < 0) | (F.col('Monthly_Inhand_Salary') < 0) | (F.col('Outstanding_Debt') < 0), \n",
    "        1).otherwise(0)) \\\n",
    "    .withColumn('data_quality_issue', F.col('negative_financials_flag'))\n",
    "print(\"Flagged negative financial values\\n\")\n",
    "\n",
    "# --- LOAN_DAILY CLEANING ---\n",
    "print(\"Cleaning loan_daily dataset...\")\n",
    "# Clean integer columns: keep digits only (handle empty strings)\n",
    "loan_int_cols = ['tenure', 'installment_num', 'loan_amt', 'due_amt', 'paid_amt', 'overdue_amt', 'balance']\n",
    "for col_name in loan_int_cols:\n",
    "    silver_LMSloans = silver_LMSloans.withColumn(col_name,\n",
    "        F.when(F.trim(F.regexp_replace(col_name, r'[^0-9]', '')) == '', None)\n",
    "         .otherwise(F.regexp_replace(col_name, r'[^0-9]', '').cast(IntegerType())))\n",
    "print(f\"Cleaned {len(loan_int_cols)} columns with r\\\"[^0-9]\\\" → IntegerType\")\n",
    "\n",
    "# Flag quality issues\n",
    "silver_LMSloans = silver_LMSloans \\\n",
    "    .withColumn('negative_loan_vals_flag', F.when(\n",
    "        (F.col('loan_amt') < 0) | (F.col('due_amt') < 0) | (F.col('paid_amt') < 0) | (F.col('overdue_amt') < 0),\n",
    "        1).otherwise(0)) \\\n",
    "    .withColumn('data_quality_issue', F.col('negative_loan_vals_flag'))\n",
    "print(\"Flagged negative loan values\\n\")\n",
    "\n",
    "# --- CLICKSTREAM CLEANING ---\n",
    "print(\"Cleaning clickstream dataset\")\n",
    "# Clean signed integer columns (keep digits and minus sign, handle empty strings)\n",
    "for i in range(1, 21):\n",
    "    silver_featureCS = silver_featureCS.withColumn(f'fe_{i}',\n",
    "        F.when(F.trim(F.regexp_replace(f'fe_{i}', r'[^0-9-]', '')) == '', None)\n",
    "         .otherwise(F.regexp_replace(f'fe_{i}', r'[^0-9-]', '').cast(IntegerType())))\n",
    "print(\"Cleaned 20 features (fe_1 to fe_20) with r\\\"[^0-9-]\\\" → IntegerType\\n\")\n",
    "\n",
    "# --- FLAG CUSTOMERS ---\n",
    "print(\"Identifying flagged customers\")\n",
    "flagged_attr = silver_featureAttr.filter(F.col('data_quality_issue') == 1).select('Customer_ID')\n",
    "flagged_fin = silver_featureFin.filter(F.col('data_quality_issue') == 1).select('Customer_ID')\n",
    "flagged_loan = silver_LMSloans.filter(F.col('data_quality_issue') == 1).select('Customer_ID')\n",
    "all_flagged = flagged_attr.union(flagged_fin).union(flagged_loan).distinct()\n",
    "\n",
    "# Calculate flagging statistics\n",
    "total_customers = silver_featureAttr.select('Customer_ID').union(\n",
    "    silver_featureFin.select('Customer_ID')).union(\n",
    "    silver_LMSloans.select('Customer_ID')).union(\n",
    "    silver_featureCS.select('Customer_ID')).distinct().count()\n",
    "flagged_count = all_flagged.count()\n",
    "pct = (flagged_count / total_customers * 100.0) if total_customers else 0.0\n",
    "print(f\"Flagged {flagged_count}/{total_customers} customers ({pct:.2f}%) for removal\\n\")\n",
    "\n",
    "# Prepare clean datasets (drop quality flag columns)\n",
    "silver_dfs = {\n",
    "    'attributes': silver_featureAttr.drop('age_flag', 'ssn_flag', 'data_quality_issue'),\n",
    "    'financials': silver_featureFin.drop('negative_financials_flag', 'data_quality_issue'),\n",
    "    'loan_daily': silver_LMSloans.drop('negative_loan_vals_flag', 'data_quality_issue'),\n",
    "    'clickstream': silver_featureCS\n",
    "}\n",
    "\n",
    "# Remove flagged customers\n",
    "filtered_dfs = remove_flagged_customers(silver_dfs, all_flagged)\n",
    "\n",
    "for name, df in filtered_dfs.items():\n",
    "    print(f\"\\n{name.upper()} DataFrame Info:\")\n",
    "    print(f\"Rows: {df.count()}\")\n",
    "    df.printSchema()\n",
    "\n",
    "print(\"Silver Cleaning Complete\\n\")\n",
    "\n",
    "\n",
    "# Save data\n",
    "output_path = 'datamart/silver'\n",
    "\n",
    "for name, df in filtered_dfs.items():\n",
    "    output_file = os.path.join(output_path, f'{name}.parquet')\n",
    "    write_parquet(df, output_file)\n",
    "    print(f\"Saved {name}\")\n",
    "\n",
    "print(\"Save Complete\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f141bcb9",
   "metadata": {},
   "source": [
    "### Gold Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "442ba632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from datamart/silver\\attributes.parquet successfully.\n",
      "Data read from datamart/silver\\financials.parquet successfully.\n",
      "Data read from datamart/silver\\loan_daily.parquet successfully.\n",
      "Data read from datamart/silver\\clickstream.parquet successfully.\n",
      "Silver files loaded\n",
      "Label store created\n",
      "Time-aware filtering applied\n",
      "NULL imputation completed\n",
      "Aggregations completed\n",
      "Feature engineering completed\n",
      "Data written to datamart/gold/gold_features.parquet successfully.\n",
      "Gold features saved\n",
      "Data written to datamart/gold/label_store.parquet successfully.\n",
      "Label store saved\n",
      "\n",
      "Gold Layer Completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Configuration\n",
    "PREDICTION_MOB = 3\n",
    "OBSERVATION_MOB = 6\n",
    "OVERDUE_THRESHOLD = 0\n",
    "\n",
    "if os.path.exists('datamart/gold') == False:\n",
    "    os.makedirs('datamart/gold', exist_ok=True)\n",
    "    \n",
    "    # Load silver data\n",
    "    silver_path = 'datamart/silver'\n",
    "    attributes_df = read_parquet(spark, os.path.join(silver_path, 'attributes.parquet'))\n",
    "    financials_df = read_parquet(spark, os.path.join(silver_path, 'financials.parquet'))\n",
    "    loan_daily_df = read_parquet(spark, os.path.join(silver_path, 'loan_daily.parquet'))\n",
    "    clickstream_df = read_parquet(spark, os.path.join(silver_path, 'clickstream.parquet'))\n",
    "    print(\"Silver files loaded\")\n",
    "    \n",
    "    # Create label store\n",
    "    loan_info = loan_daily_df.select(\"loan_id\", \"Customer_ID\", \"loan_start_date\").distinct()\n",
    "    labels_df = loan_info \\\n",
    "        .withColumn(\"prediction_date\", F.add_months(F.col(\"loan_start_date\"), PREDICTION_MOB)) \\\n",
    "        .withColumn(\"observation_date\", F.add_months(F.col(\"loan_start_date\"), OBSERVATION_MOB))\n",
    "    \n",
    "    default_events = loan_daily_df.filter(\n",
    "        (F.col(\"installment_num\") >= PREDICTION_MOB) & \n",
    "        (F.col(\"installment_num\") <= OBSERVATION_MOB) &\n",
    "        (F.col(\"overdue_amt\") > OVERDUE_THRESHOLD)\n",
    "    ).select(\"loan_id\").distinct().withColumn(\"defaulted_flag\", F.lit(1))\n",
    "    \n",
    "    label_store = labels_df.join(default_events, \"loan_id\", \"left\") \\\n",
    "        .withColumn(\"label\", F.when(F.col(\"defaulted_flag\").isNotNull(), 1).otherwise(0)) \\\n",
    "        .select(\"Customer_ID\", \"loan_id\", \"prediction_date\", \"observation_date\", \"label\")\n",
    "    print(\"Label store created\")\n",
    "    \n",
    "    # Time-aware filtering\n",
    "    loan_application = loan_daily_df.filter(F.col(\"installment_num\") == 0) \\\n",
    "        .select(\"loan_id\", \"Customer_ID\", \"loan_amt\", \"tenure\", \"loan_start_date\")\n",
    "    \n",
    "    clickstream_history = clickstream_df.join(\n",
    "        loan_application.select(\"Customer_ID\", \"loan_start_date\"), \"Customer_ID\"\n",
    "    ).filter(F.col(\"snapshot_date\") < F.col(\"loan_start_date\"))\n",
    "    \n",
    "    loan_history = loan_daily_df.join(\n",
    "        label_store.select(\"loan_id\", \"prediction_date\"), \"loan_id\"\n",
    "    ).filter((F.col(\"installment_num\") >= 0) & (F.col(\"installment_num\") < PREDICTION_MOB))\n",
    "    print(\"Time-aware filtering applied\")\n",
    "    \n",
    "    # Impute NULLs with median\n",
    "    numeric_cols = ['Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card',\n",
    "                    'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment',\n",
    "                    'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Outstanding_Debt',\n",
    "                    'Credit_Utilization_Ratio', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Monthly_Balance']\n",
    "    \n",
    "    for col_name in numeric_cols:\n",
    "        median_val = financials_df.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "        financials_df = financials_df.withColumn(col_name, F.coalesce(F.col(col_name), F.lit(median_val)))\n",
    "    \n",
    "    age_median = attributes_df.approxQuantile('Age', [0.5], 0.01)[0]\n",
    "    attributes_df = attributes_df.withColumn('Age', F.coalesce(F.col('Age'), F.lit(age_median)))\n",
    "    print(\"NULL imputation completed\")\n",
    "    \n",
    "    # Aggregate loan history\n",
    "    loan_agg = loan_history.groupBy(\"Customer_ID\").agg(\n",
    "        F.sum(\"paid_amt\").alias(\"hist_total_paid\"),\n",
    "        F.sum(\"due_amt\").alias(\"hist_total_due\"),\n",
    "        F.sum(\"overdue_amt\").alias(\"hist_total_overdue_amount\")\n",
    "    ).withColumn(\"hist_Loan_Payment_Ratio\", \n",
    "        F.when(F.col(\"hist_total_due\") > 0, F.col(\"hist_total_paid\") / F.col(\"hist_total_due\")).otherwise(1.0))\n",
    "    \n",
    "    # Aggregate clickstream (fe_10 only - strongest predictor)\n",
    "    clickstream_agg = clickstream_history.groupBy(\"Customer_ID\").agg(\n",
    "        F.mean(\"fe_10\").alias(\"fe_10_mean\"),\n",
    "        F.stddev(\"fe_10\").alias(\"fe_10_std\")\n",
    "    )\n",
    "    print(\"Aggregations completed\")\n",
    "    \n",
    "    # Get latest snapshots\n",
    "    attributes_as_of = attributes_df.join(\n",
    "        label_store.select(\"Customer_ID\", \"prediction_date\"), \"Customer_ID\"\n",
    "    ).filter(F.col(\"snapshot_date\") <= F.col(\"prediction_date\")) \\\n",
    "     .groupBy(\"Customer_ID\").agg(F.max('snapshot_date').alias('latest_snapshot'))\n",
    "    \n",
    "    attributes_latest = attributes_df.join(\n",
    "        attributes_as_of, \n",
    "        on=[attributes_df.Customer_ID == attributes_as_of.Customer_ID, \n",
    "            attributes_df.snapshot_date == attributes_as_of.latest_snapshot]\n",
    "    ).select(attributes_df[\"*\"])\n",
    "    \n",
    "    financials_as_of = financials_df.join(\n",
    "        label_store.select(\"Customer_ID\", \"prediction_date\"), \"Customer_ID\"\n",
    "    ).filter(F.col(\"snapshot_date\") <= F.col(\"prediction_date\")) \\\n",
    "     .groupBy(\"Customer_ID\").agg(F.max('snapshot_date').alias('latest_snapshot'))\n",
    "    \n",
    "    financials_latest = financials_df.join(\n",
    "        financials_as_of, \n",
    "        on=[financials_df.Customer_ID == financials_as_of.Customer_ID, \n",
    "            financials_df.snapshot_date == financials_as_of.latest_snapshot]\n",
    "    ).select(financials_df[\"*\"])\n",
    "    \n",
    "    # Engineer features\n",
    "    years_col = F.regexp_extract(F.col(\"Credit_History_Age\"), r\"(\\d+)\\s+Years\", 1).cast(IntegerType())\n",
    "    months_col = F.regexp_extract(F.col(\"Credit_History_Age\"), r\"(\\d+)\\s+Months\", 1).cast(IntegerType())\n",
    "    \n",
    "    financials_features = financials_latest.withColumn(\n",
    "        \"Credit_History_Months\", F.coalesce(years_col, F.lit(0)) * 12 + F.coalesce(months_col, F.lit(0))\n",
    "    ).withColumn(\"DTI\", F.col(\"Total_EMI_per_month\") / F.col(\"Monthly_Inhand_Salary\")\n",
    "    ).withColumn(\"Savings_Ratio\", F.col(\"Amount_invested_monthly\") / F.col(\"Monthly_Inhand_Salary\")\n",
    "    ).withColumn(\"Monthly_Surplus\", F.col(\"Monthly_Inhand_Salary\") - F.col(\"Total_EMI_per_month\") - F.col(\"Amount_invested_monthly\")\n",
    "    ).withColumn(\"Debt_to_Annual_Income\", F.col(\"Outstanding_Debt\") / F.col(\"Annual_Income\"))\n",
    "    print(\"Feature engineering completed\")\n",
    "    \n",
    "    # Join all features\n",
    "    gold_features = label_store \\\n",
    "        .join(loan_application.select(\"loan_id\", \"loan_amt\", \"tenure\"), \"loan_id\", \"inner\") \\\n",
    "        .join(attributes_latest.select(\"Customer_ID\", \"Age\", \"Occupation\"), \"Customer_ID\", \"inner\") \\\n",
    "        .join(financials_features.drop(\"snapshot_date\"), \"Customer_ID\", \"left\") \\\n",
    "        .join(clickstream_agg, \"Customer_ID\", \"left\") \\\n",
    "        .join(loan_agg, \"Customer_ID\", \"left\")\n",
    "    \n",
    "    # Filter to 15 safe features\n",
    "    safe_features = ['Credit_History_Months', 'Credit_Mix', 'Age', 'Monthly_Inhand_Salary', 'Occupation',\n",
    "                     'loan_amt', 'tenure', 'Interest_Rate', 'fe_10_mean', 'fe_10_std',\n",
    "                     'Savings_Ratio', 'DTI', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Amount_invested_monthly']\n",
    "    \n",
    "    id_cols = ['Customer_ID', 'loan_id', 'prediction_date', 'observation_date', 'label']\n",
    "    selected_cols = id_cols + [c for c in safe_features if c in gold_features.columns]\n",
    "    gold_features_filtered = gold_features.select(*selected_cols)\n",
    "    \n",
    "    # Save gold features\n",
    "    write_parquet(gold_features_filtered, 'datamart/gold/gold_features.parquet')\n",
    "    print(\"Gold features saved\")\n",
    "    \n",
    "    # Save label store\n",
    "    write_parquet(label_store, 'datamart/gold/label_store.parquet')\n",
    "    print(\"Label store saved\")\n",
    "    \n",
    "else:\n",
    "    print(\"Directory already exists\")\n",
    "\n",
    "print(\"\\nGold Layer Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c9fa7",
   "metadata": {},
   "source": [
    "### ML Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df399ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "MODEL_STORE_PATH = 'model_store'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "if os.path.exists(MODEL_STORE_PATH) == False:\n",
    "    os.makedirs(MODEL_STORE_PATH, exist_ok=True)\n",
    "    \n",
    "    # Load gold features\n",
    "    gold_df = pd.read_parquet('datamart/gold/gold_features.parquet')\n",
    "    print(f\"Loaded {len(gold_df)} records from gold features\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    feature_cols = ['Credit_History_Months', 'Age', 'Monthly_Inhand_Salary', 'loan_amt', 'tenure',\n",
    "                    'Interest_Rate', 'fe_10_mean', 'fe_10_std', 'Savings_Ratio', 'DTI',\n",
    "                    'Num_Bank_Accounts', 'Num_Credit_Card', 'Amount_invested_monthly']\n",
    "    \n",
    "    categorical_cols = ['Credit_Mix', 'Occupation']\n",
    "    target_col = 'label'\n",
    "    \n",
    "    # Handle categorical features\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        gold_df[col] = le.fit_transform(gold_df[col].fillna('Unknown'))\n",
    "        label_encoders[col] = le\n",
    "        feature_cols.append(col)\n",
    "    \n",
    "    # Handle missing values\n",
    "    gold_df[feature_cols] = gold_df[feature_cols].fillna(gold_df[feature_cols].median())\n",
    "    \n",
    "    X = gold_df[feature_cols]\n",
    "    y = gold_df[target_col]\n",
    "    \n",
    "    # Train-test split (80-20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
    "    print(f\"Train: {len(X_train)} samples, Test: {len(X_test)} samples\")\n",
    "    print(f\"Train default rate: {y_train.mean():.2%}, Test default rate: {y_test.mean():.2%}\")\n",
    "    \n",
    "    # Define models to train\n",
    "    models = {\n",
    "        'logistic_regression': LogisticRegression(max_iter=1000, random_state=RANDOM_STATE, class_weight='balanced'),\n",
    "        'random_forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=RANDOM_STATE, class_weight='balanced'),\n",
    "        'gradient_boosting': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=RANDOM_STATE)\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    model_results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        y_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "        y_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Metrics\n",
    "        train_auc = roc_auc_score(y_train, y_proba_train)\n",
    "        test_auc = roc_auc_score(y_test, y_proba_test)\n",
    "        \n",
    "        model_results[name] = {\n",
    "            'model': model,\n",
    "            'train_auc': train_auc,\n",
    "            'test_auc': test_auc,\n",
    "            'y_pred_test': y_pred_test,\n",
    "            'y_proba_test': y_proba_test\n",
    "        }\n",
    "        \n",
    "        print(f\"  Train AUC: {train_auc:.4f}, Test AUC: {test_auc:.4f}\")\n",
    "    \n",
    "    # Select best model by test AUC\n",
    "    best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['test_auc'])\n",
    "    best_model = model_results[best_model_name]['model']\n",
    "    best_test_auc = model_results[best_model_name]['test_auc']\n",
    "    \n",
    "    print(f\"\\nBest model: {best_model_name} (Test AUC: {best_test_auc:.4f})\")\n",
    "    \n",
    "    # Save best model\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_metadata = {\n",
    "        'model_name': best_model_name,\n",
    "        'timestamp': timestamp,\n",
    "        'train_samples': len(X_train),\n",
    "        'test_samples': len(X_test),\n",
    "        'train_auc': float(model_results[best_model_name]['train_auc']),\n",
    "        'test_auc': float(best_test_auc),\n",
    "        'feature_columns': feature_cols,\n",
    "        'label_encoders': {k: v.classes_.tolist() for k, v in label_encoders.items()}\n",
    "    }\n",
    "    \n",
    "    joblib.dump(best_model, f'{MODEL_STORE_PATH}/best_model_{timestamp}.pkl')\n",
    "    joblib.dump(label_encoders, f'{MODEL_STORE_PATH}/label_encoders_{timestamp}.pkl')\n",
    "    with open(f'{MODEL_STORE_PATH}/model_metadata_{timestamp}.json', 'w') as f:\n",
    "        json.dump(model_metadata, f, indent=2)\n",
    "    \n",
    "    # Save test data for monitoring\n",
    "    test_data = X_test.copy()\n",
    "    test_data['true_label'] = y_test.values\n",
    "    test_data['predicted_label'] = model_results[best_model_name]['y_pred_test']\n",
    "    test_data['predicted_proba'] = model_results[best_model_name]['y_proba_test']\n",
    "    test_data.to_parquet(f'{MODEL_STORE_PATH}/test_predictions_{timestamp}.parquet', index=False)\n",
    "    \n",
    "    print(f\"\\nModel artifacts saved to {MODEL_STORE_PATH}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Model store already exists\")\n",
    "\n",
    "print(\"\\nML Training Pipeline Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a22f4a0",
   "metadata": {},
   "source": [
    "### ML Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f6c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "INFERENCE_OUTPUT_PATH = 'datamart/gold'\n",
    "\n",
    "if not os.path.exists(f'{INFERENCE_OUTPUT_PATH}/model_predictions.parquet'):\n",
    "    \n",
    "    # Find latest model\n",
    "    model_files = [f for f in os.listdir(MODEL_STORE_PATH) if f.startswith('best_model_')]\n",
    "    if not model_files:\n",
    "        raise FileNotFoundError(\"No trained model found. Please run training pipeline first.\")\n",
    "    \n",
    "    latest_model_file = sorted(model_files)[-1]\n",
    "    timestamp = latest_model_file.replace('best_model_', '').replace('.pkl', '')\n",
    "    \n",
    "    # Load model artifacts\n",
    "    model = joblib.load(f'{MODEL_STORE_PATH}/{latest_model_file}')\n",
    "    label_encoders = joblib.load(f'{MODEL_STORE_PATH}/label_encoders_{timestamp}.pkl')\n",
    "    with open(f'{MODEL_STORE_PATH}/model_metadata_{timestamp}.json', 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    print(f\"Loaded model: {metadata['model_name']} (Test AUC: {metadata['test_auc']:.4f})\")\n",
    "    \n",
    "    # Load gold features for inference\n",
    "    gold_df = pd.read_parquet('datamart/gold/gold_features.parquet')\n",
    "    inference_df = gold_df.copy()\n",
    "    \n",
    "    # Prepare features (same as training)\n",
    "    feature_cols = metadata['feature_columns']\n",
    "    categorical_cols = ['Credit_Mix', 'Occupation']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        le = label_encoders[col]\n",
    "        inference_df[col] = inference_df[col].fillna('Unknown')\n",
    "        inference_df[col] = inference_df[col].apply(lambda x: x if x in le.classes_ else 'Unknown')\n",
    "        inference_df[col] = le.transform(inference_df[col])\n",
    "    \n",
    "    inference_df[feature_cols] = inference_df[feature_cols].fillna(inference_df[feature_cols].median())\n",
    "    \n",
    "    # Make predictions\n",
    "    X_inference = inference_df[feature_cols]\n",
    "    predictions = model.predict(X_inference)\n",
    "    probabilities = model.predict_proba(X_inference)[:, 1]\n",
    "    \n",
    "    # Create predictions table\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'Customer_ID': inference_df['Customer_ID'],\n",
    "        'loan_id': inference_df['loan_id'],\n",
    "        'prediction_date': inference_df['prediction_date'],\n",
    "        'observation_date': inference_df['observation_date'],\n",
    "        'true_label': inference_df['label'],\n",
    "        'predicted_label': predictions,\n",
    "        'predicted_proba': probabilities,\n",
    "        'model_name': metadata['model_name'],\n",
    "        'model_version': timestamp,\n",
    "        'inference_timestamp': datetime.now()\n",
    "    })\n",
    "    \n",
    "    # Save predictions\n",
    "    predictions_df.to_parquet(f'{INFERENCE_OUTPUT_PATH}/model_predictions.parquet', \n",
    "                              index=False, compression='gzip', engine='pyarrow')\n",
    "    print(f\"Predictions saved: {len(predictions_df)} records\")\n",
    "    print(f\"Predicted default rate: {predictions.mean():.2%}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Predictions already exist\")\n",
    "    predictions_df = pd.read_parquet(f'{INFERENCE_OUTPUT_PATH}/model_predictions.parquet')\n",
    "    print(f\"Loaded existing predictions: {len(predictions_df)} records\")\n",
    "\n",
    "print(\"\\nML Inference Pipeline Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a595546",
   "metadata": {},
   "source": [
    "### Model Monitoring Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f15882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                            roc_auc_score, confusion_matrix, classification_report)\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "MONITORING_OUTPUT_PATH = 'datamart/gold'\n",
    "\n",
    "if not os.path.exists(f'{MONITORING_OUTPUT_PATH}/model_monitoring.parquet'):\n",
    "    \n",
    "    # Load predictions\n",
    "    predictions_df = pd.read_parquet(f'{MONITORING_OUTPUT_PATH}/model_predictions.parquet')\n",
    "    print(f\"Monitoring {len(predictions_df)} predictions\")\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    y_true = predictions_df['true_label']\n",
    "    y_pred = predictions_df['predicted_label']\n",
    "    y_proba = predictions_df['predicted_proba']\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    \n",
    "    print(f\"\\nOverall Performance:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    print(f\"  AUC-ROC:   {auc:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"  True Negatives:  {tn}\")\n",
    "    print(f\"  False Positives: {fp}\")\n",
    "    print(f\"  False Negatives: {fn}\")\n",
    "    print(f\"  True Positives:  {tp}\")\n",
    "    \n",
    "    # Time-based monitoring (by prediction_date)\n",
    "    predictions_df['prediction_month'] = pd.to_datetime(predictions_df['prediction_date']).dt.to_period('M')\n",
    "    \n",
    "    monthly_metrics = []\n",
    "    for month in predictions_df['prediction_month'].unique():\n",
    "        month_data = predictions_df[predictions_df['prediction_month'] == month]\n",
    "        \n",
    "        if len(month_data) > 0:\n",
    "            y_true_month = month_data['true_label']\n",
    "            y_pred_month = month_data['predicted_label']\n",
    "            y_proba_month = month_data['predicted_proba']\n",
    "            \n",
    "            monthly_metrics.append({\n",
    "                'period': str(month),\n",
    "                'num_predictions': len(month_data),\n",
    "                'actual_default_rate': y_true_month.mean(),\n",
    "                'predicted_default_rate': y_pred_month.mean(),\n",
    "                'accuracy': accuracy_score(y_true_month, y_pred_month),\n",
    "                'precision': precision_score(y_true_month, y_pred_month, zero_division=0),\n",
    "                'recall': recall_score(y_true_month, y_pred_month, zero_division=0),\n",
    "                'f1_score': f1_score(y_true_month, y_pred_month, zero_division=0),\n",
    "                'auc_roc': roc_auc_score(y_true_month, y_proba_month) if len(np.unique(y_true_month)) > 1 else np.nan\n",
    "            })\n",
    "    \n",
    "    monthly_metrics_df = pd.DataFrame(monthly_metrics)\n",
    "    \n",
    "    # Data drift detection (distribution shift)\n",
    "    predictions_df['proba_bucket'] = pd.cut(predictions_df['predicted_proba'], \n",
    "                                            bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "                                            labels=['0.0-0.2', '0.2-0.4', '0.4-0.6', '0.6-0.8', '0.8-1.0'])\n",
    "    \n",
    "    drift_metrics = []\n",
    "    for month in predictions_df['prediction_month'].unique():\n",
    "        month_data = predictions_df[predictions_df['prediction_month'] == month]\n",
    "        distribution = month_data['proba_bucket'].value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        drift_metrics.append({\n",
    "            'period': str(month),\n",
    "            'proba_distribution': distribution,\n",
    "            'mean_proba': month_data['predicted_proba'].mean(),\n",
    "            'std_proba': month_data['predicted_proba'].std()\n",
    "        })\n",
    "    \n",
    "    drift_metrics_df = pd.DataFrame(drift_metrics)\n",
    "    \n",
    "    # Create monitoring summary\n",
    "    monitoring_summary = {\n",
    "        'monitoring_timestamp': datetime.now(),\n",
    "        'model_version': predictions_df['model_version'].iloc[0],\n",
    "        'total_predictions': len(predictions_df),\n",
    "        'overall_metrics': {\n",
    "            'accuracy': float(accuracy),\n",
    "            'precision': float(precision),\n",
    "            'recall': float(recall),\n",
    "            'f1_score': float(f1),\n",
    "            'auc_roc': float(auc)\n",
    "        },\n",
    "        'confusion_matrix': {\n",
    "            'true_negatives': int(tn),\n",
    "            'false_positives': int(fp),\n",
    "            'false_negatives': int(fn),\n",
    "            'true_positives': int(tp)\n",
    "        },\n",
    "        'monthly_performance': monthly_metrics_df.to_dict('records'),\n",
    "        'drift_analysis': drift_metrics_df.to_dict('records')\n",
    "    }\n",
    "    \n",
    "    # Save monitoring results\n",
    "    monitoring_df = pd.DataFrame([monitoring_summary])\n",
    "    monitoring_df.to_parquet(f'{MONITORING_OUTPUT_PATH}/model_monitoring.parquet', \n",
    "                            index=False, compression='gzip', engine='pyarrow')\n",
    "    \n",
    "    # Save monthly metrics separately for easier querying\n",
    "    monthly_metrics_df.to_parquet(f'{MONITORING_OUTPUT_PATH}/monthly_performance.parquet',\n",
    "                                  index=False, compression='gzip', engine='pyarrow')\n",
    "    \n",
    "    print(f\"\\nMonitoring results saved to {MONITORING_OUTPUT_PATH}\")\n",
    "    print(f\"Tracked {len(monthly_metrics_df)} time periods\")\n",
    "    \n",
    "else:\n",
    "    print(\"Monitoring results already exist\")\n",
    "\n",
    "print(\"\\nModel Monitoring Pipeline Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da40d18",
   "metadata": {},
   "source": [
    "### Model Visualization & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e935616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "# Load data\n",
    "predictions_df = pd.read_parquet('datamart/gold/model_predictions.parquet')\n",
    "monthly_df = pd.read_parquet('datamart/gold/monthly_performance.parquet')\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Model Performance & Stability Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. ROC Curve\n",
    "y_true = predictions_df['true_label']\n",
    "y_proba = predictions_df['predicted_proba']\n",
    "fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_true, y_proba)\n",
    "\n",
    "axes[0, 0].plot(fpr, tpr, label=f'AUC = {auc:.4f}', linewidth=2)\n",
    "axes[0, 0].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "axes[0, 0].set_xlabel('False Positive Rate')\n",
    "axes[0, 0].set_ylabel('True Positive Rate')\n",
    "axes[0, 0].set_title('ROC Curve')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "axes[0, 1].plot(recall, precision, linewidth=2)\n",
    "axes[0, 1].set_xlabel('Recall')\n",
    "axes[0, 1].set_ylabel('Precision')\n",
    "axes[0, 1].set_title('Precision-Recall Curve')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Confusion Matrix\n",
    "y_pred = predictions_df['predicted_label']\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 2], cbar=False)\n",
    "axes[0, 2].set_xlabel('Predicted')\n",
    "axes[0, 2].set_ylabel('Actual')\n",
    "axes[0, 2].set_title('Confusion Matrix')\n",
    "\n",
    "# 4. Performance Over Time (AUC)\n",
    "monthly_df_sorted = monthly_df.sort_values('period')\n",
    "axes[1, 0].plot(range(len(monthly_df_sorted)), monthly_df_sorted['auc_roc'], \n",
    "                marker='o', linewidth=2, markersize=8)\n",
    "axes[1, 0].axhline(y=monthly_df_sorted['auc_roc'].mean(), color='r', \n",
    "                   linestyle='--', label=f\"Mean: {monthly_df_sorted['auc_roc'].mean():.4f}\")\n",
    "axes[1, 0].set_xlabel('Time Period')\n",
    "axes[1, 0].set_ylabel('AUC-ROC')\n",
    "axes[1, 0].set_title('Model Stability - AUC Over Time')\n",
    "axes[1, 0].set_xticks(range(len(monthly_df_sorted)))\n",
    "axes[1, 0].set_xticklabels(monthly_df_sorted['period'], rotation=45, ha='right')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Actual vs Predicted Default Rates\n",
    "x_pos = np.arange(len(monthly_df_sorted))\n",
    "width = 0.35\n",
    "axes[1, 1].bar(x_pos - width/2, monthly_df_sorted['actual_default_rate'], \n",
    "               width, label='Actual', alpha=0.8)\n",
    "axes[1, 1].bar(x_pos + width/2, monthly_df_sorted['predicted_default_rate'], \n",
    "               width, label='Predicted', alpha=0.8)\n",
    "axes[1, 1].set_xlabel('Time Period')\n",
    "axes[1, 1].set_ylabel('Default Rate')\n",
    "axes[1, 1].set_title('Actual vs Predicted Default Rates')\n",
    "axes[1, 1].set_xticks(x_pos)\n",
    "axes[1, 1].set_xticklabels(monthly_df_sorted['period'], rotation=45, ha='right')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 6. Prediction Distribution\n",
    "axes[1, 2].hist(predictions_df['predicted_proba'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1, 2].axvline(predictions_df['predicted_proba'].mean(), color='r', \n",
    "                   linestyle='--', label=f\"Mean: {predictions_df['predicted_proba'].mean():.3f}\")\n",
    "axes[1, 2].set_xlabel('Predicted Probability')\n",
    "axes[1, 2].set_ylabel('Frequency')\n",
    "axes[1, 2].set_title('Prediction Distribution')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_performance_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Dashboard saved as 'model_performance_dashboard.png'\")\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Predictions: {len(predictions_df):,}\")\n",
    "print(f\"Overall AUC-ROC: {auc:.4f}\")\n",
    "print(f\"Mean Monthly AUC: {monthly_df_sorted['auc_roc'].mean():.4f} ± {monthly_df_sorted['auc_roc'].std():.4f}\")\n",
    "print(f\"AUC Stability: {'STABLE' if monthly_df_sorted['auc_roc'].std() < 0.05 else 'UNSTABLE'}\")\n",
    "print(f\"Actual Default Rate: {y_true.mean():.2%}\")\n",
    "print(f\"Predicted Default Rate: {y_pred.mean():.2%}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c22bd",
   "metadata": {},
   "source": [
    "### Model Governance & SOP\n",
    "\n",
    "## Model Refresh Strategy\n",
    "\n",
    "### When to Refresh the Model:\n",
    "\n",
    "**1. Performance Degradation Triggers:**\n",
    "- AUC drops below **0.70** for 2 consecutive months\n",
    "- Precision drops below **0.60** (too many false positives)\n",
    "- Recall drops below **0.50** (missing too many defaults)\n",
    "- F1-Score drops below **0.55**\n",
    "\n",
    "**2. Data Drift Triggers:**\n",
    "- Predicted default rate differs from actual by >**5%** for 2+ months\n",
    "- Distribution shift: >**20%** change in prediction probability distribution\n",
    "- Feature distribution shifts significantly (monitored via monthly stats)\n",
    "\n",
    "**3. Business Triggers:**\n",
    "- Quarterly mandatory review (every 3 months)\n",
    "- Major policy changes (new loan products, risk appetite changes)\n",
    "- Regulatory requirements\n",
    "\n",
    "**4. Time-Based Trigger:**\n",
    "- Maximum model age: **6 months** without refresh\n",
    "\n",
    "---\n",
    "\n",
    "## Model Refresh Process (SOP):\n",
    "\n",
    "### Phase 1: Alert & Assessment (Week 1)\n",
    "1. Automated monitoring detects trigger condition\n",
    "2. Data science team reviews monitoring dashboard\n",
    "3. Investigate root cause (data drift, concept drift, data quality)\n",
    "4. Create refresh decision report\n",
    "\n",
    "### Phase 2: Data Preparation (Week 2)\n",
    "1. Collect latest data (last 6 months minimum)\n",
    "2. Run bronze → silver → gold pipeline\n",
    "3. Validate data quality and feature distributions\n",
    "4. Create new training/validation/test splits (70/15/15)\n",
    "\n",
    "### Phase 3: Model Training & Validation (Week 3)\n",
    "1. Retrain all candidate models (Logistic, RF, GBM, XGBoost)\n",
    "2. Perform hyperparameter tuning\n",
    "3. Validate on holdout test set\n",
    "4. Compare new model vs. production model:\n",
    "   - AUC improvement >**2%** → proceed\n",
    "   - AUC similar ±2% → review business case\n",
    "   - AUC worse → investigate before proceeding\n",
    "\n",
    "### Phase 4: Shadow Deployment (Week 4)\n",
    "1. Deploy new model alongside production model\n",
    "2. Run both models on live data (no customer impact)\n",
    "3. Compare predictions for 1 week\n",
    "4. Check for prediction consistency and stability\n",
    "\n",
    "### Phase 5: Production Deployment (Week 5)\n",
    "1. **Blue-Green Deployment:**\n",
    "   - Deploy new model to production environment (green)\n",
    "   - Keep old model running (blue)\n",
    "   - Route 10% traffic to new model\n",
    "   - Monitor for 2 days\n",
    "   - Increase to 50% for 2 days\n",
    "   - Full cutover to new model\n",
    "   - Keep old model on standby for 1 week\n",
    "\n",
    "2. **Rollback Plan:**\n",
    "   - If AUC drops >5% → immediate rollback\n",
    "   - If error rate spikes → immediate rollback\n",
    "   - Keep previous model for 2 weeks before archival\n",
    "\n",
    "### Phase 6: Post-Deployment Monitoring (Ongoing)\n",
    "1. Daily monitoring for first week\n",
    "2. Weekly monitoring for first month\n",
    "3. Monthly monitoring thereafter\n",
    "4. Document performance in model registry\n",
    "\n",
    "---\n",
    "\n",
    "## Deployment Architecture:\n",
    "\n",
    "### Option 1: Batch Prediction (Recommended for Current Scale)\n",
    "- **Schedule:** Daily at 2 AM\n",
    "- **Process:** Load new loan applications → score → store results\n",
    "- **Latency:** <5 minutes for 10,000 loans\n",
    "- **Infrastructure:** Single VM with 8 cores, 16GB RAM\n",
    "- **Cost:** Low, suitable for current volume\n",
    "\n",
    "### Option 2: Real-Time API (Future Scale)\n",
    "- **Architecture:** REST API with model server (FastAPI/Flask)\n",
    "- **Latency:** <100ms per prediction\n",
    "- **Scaling:** Auto-scaling based on load\n",
    "- **Infrastructure:** Kubernetes cluster\n",
    "- **Cost:** Higher, use when volume >100k loans/day\n",
    "\n",
    "---\n",
    "\n",
    "## Model Registry & Versioning:\n",
    "\n",
    "### Versioning Schema:\n",
    "```\n",
    "v{YEAR}.{MONTH}.{INCREMENT}\n",
    "Example: v2025.10.01\n",
    "```\n",
    "\n",
    "### Stored Artifacts:\n",
    "1. **Model binary** (.pkl file)\n",
    "2. **Metadata** (performance metrics, training date, features)\n",
    "3. **Label encoders** (for categorical features)\n",
    "4. **Training data statistics** (for drift detection)\n",
    "5. **Model card** (documentation, known limitations)\n",
    "\n",
    "---\n",
    "\n",
    "## Monitoring Dashboard KPIs:\n",
    "\n",
    "### Red (Critical):\n",
    "- AUC < 0.65\n",
    "- Precision < 0.50\n",
    "- Recall < 0.40\n",
    "\n",
    "### Yellow (Warning):\n",
    "- AUC 0.65-0.70\n",
    "- Precision 0.50-0.60  \n",
    "- Recall 0.40-0.50\n",
    "- Prediction drift >5%\n",
    "\n",
    "### Green (Healthy):\n",
    "- AUC > 0.70\n",
    "- Precision > 0.60\n",
    "- Recall > 0.50\n",
    "- Prediction drift <3%\n",
    "\n",
    "---\n",
    "\n",
    "## Roles & Responsibilities:\n",
    "\n",
    "| Role | Responsibility |\n",
    "|------|----------------|\n",
    "| **Data Scientist** | Model development, training, validation, documentation |\n",
    "| **ML Engineer** | Deployment, monitoring, infrastructure, CI/CD |\n",
    "| **Data Engineer** | Pipeline maintenance, data quality, feature engineering |\n",
    "| **Product Manager** | Business requirements, approval for model refresh |\n",
    "| **Risk Manager** | Model risk assessment, compliance validation |\n",
    "\n",
    "---\n",
    "\n",
    "## Compliance & Audit:\n",
    "\n",
    "1. **Model Risk Management:**\n",
    "   - Quarterly model validation by independent team\n",
    "   - Annual regulatory review\n",
    "   - Document all model changes\n",
    "\n",
    "2. **Explainability:**\n",
    "   - Maintain feature importance rankings\n",
    "   - Provide SHAP values for key decisions\n",
    "   - Document model limitations\n",
    "\n",
    "3. **Bias Testing:**\n",
    "   - Monthly fairness metrics by demographic groups\n",
    "   - Disparate impact testing\n",
    "   - Adverse action reasons for declined loans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f96f0",
   "metadata": {},
   "source": [
    "## 📊 End-to-End ML Pipeline Summary\n",
    "\n",
    "### Pipeline Architecture:\n",
    "\n",
    "```\n",
    "Bronze → Silver → Gold → ML Training → Inference → Monitoring → Visualization\n",
    "```\n",
    "\n",
    "### Completed Components:\n",
    "\n",
    "✅ **1. Model Training Pipeline**\n",
    "- Trains 3 models: Logistic Regression, Random Forest, Gradient Boosting\n",
    "- Performs 80-20 train-test split with stratification\n",
    "- Selects best model based on Test AUC\n",
    "- Saves model artifacts to `model_store/`\n",
    "\n",
    "✅ **2. Model Inference Pipeline**  \n",
    "- Loads best model from model store\n",
    "- Generates predictions for all loans\n",
    "- Saves predictions to `datamart/gold/model_predictions.parquet`\n",
    "\n",
    "✅ **3. Model Monitoring Pipeline**\n",
    "- Calculates performance metrics (Accuracy, Precision, Recall, F1, AUC)\n",
    "- Tracks performance over time (monthly)\n",
    "- Detects data drift in prediction distributions\n",
    "- Saves monitoring results to `datamart/gold/model_monitoring.parquet`\n",
    "\n",
    "✅ **4. Visualization Dashboard**\n",
    "- ROC Curve & AUC visualization\n",
    "- Precision-Recall Curve\n",
    "- Confusion Matrix heatmap\n",
    "- Performance stability over time\n",
    "- Actual vs Predicted default rates\n",
    "- Prediction distribution analysis\n",
    "\n",
    "✅ **5. Model Governance & SOP**\n",
    "- Clear trigger conditions for model refresh\n",
    "- 5-phase refresh process (Assessment → Deployment)\n",
    "- Blue-green deployment strategy with rollback plan\n",
    "- Model versioning and registry structure\n",
    "- Monitoring KPI thresholds (Red/Yellow/Green)\n",
    "- Roles & responsibilities matrix\n",
    "\n",
    "### Data Lineage:\n",
    "\n",
    "```\n",
    "data/*.csv \n",
    "  → datamart/bronze/*.parquet (raw ingestion)\n",
    "  → datamart/silver/*.parquet (cleaned & validated)  \n",
    "  → datamart/gold/gold_features.parquet (engineered features)\n",
    "  → model_store/best_model_*.pkl (trained model)\n",
    "  → datamart/gold/model_predictions.parquet (inference results)\n",
    "  → datamart/gold/model_monitoring.parquet (monitoring metrics)\n",
    "  → model_performance_dashboard.png (visualization)\n",
    "```\n",
    "\n",
    "### Key Metrics:\n",
    "\n",
    "| Metric | Threshold | Status |\n",
    "|--------|-----------|--------|\n",
    "| AUC-ROC | > 0.70 | ✅ Monitor |\n",
    "| Precision | > 0.60 | ✅ Monitor |\n",
    "| Recall | > 0.50 | ✅ Monitor |\n",
    "| F1-Score | > 0.55 | ✅ Monitor |\n",
    "| Prediction Drift | < 5% | ✅ Monitor |\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Run all pipeline cells in sequence\n",
    "2. Review model performance dashboard\n",
    "3. Schedule monthly monitoring jobs\n",
    "4. Implement automated alerting for threshold breaches\n",
    "5. Set up quarterly model review calendar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
